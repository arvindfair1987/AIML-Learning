# Multivariable Calculus — Clean Notes (with All Formulae)

---

## Introduction

Welcome to the session on **Multivariable Calculus**.

Calculus is one of the most important branches of mathematics and has extensive applications in **data science and machine learning**.

At its core, calculus is the mathematical study of **continuous change**. In machine learning, calculus is heavily used in **optimisation techniques**, which are the backbone of most learning algorithms.

You are already familiar with basic calculus topics such as **limits, derivatives, and integration** from high school. This session focuses on revising and extending those ideas using **minimal mathematics**, with emphasis on intuition and applications.

---

## Session Outline

This session is divided into the following segments:

1. Functions and Derivatives
2. Critical Points – Maxima and Minima
3. Multivariable Functions
4. Partial and Total Derivatives
5. Gradients

---

## Learning Outcomes

By the end of this session, you should be able to:

* Understand the concept of functions and derivatives
* Perform differentiation of univariate functions
* Find critical points, maxima, and minima
* Understand multivariable functions and their partial and total derivatives

---

## Functions: A Quick Revision

A **function** is a mapping between inputs and outputs.

If a function takes an input ( x ) and produces an output ( y ), we write:

$$
y = f(x)
$$

Here:

* ( x ) is the **argument** (input)
* ( f(x) ) is the **value** (output)

---

### Example

Consider the function:

$$
f(x) = x^2
$$

Then,

$$
f(1) = 1,\quad f(2) = 4,\quad f(3) = 9
$$

---

### Additional Reading

You can explore graphs of common functions in a **Common Functions Reference**.

---

## Derivatives: Rate of Change

The study of functions naturally leads to the study of how functions **change**.

The **derivative** measures the **instantaneous rate of change** of one variable with respect to another.

If ( y ) depends on ( x ), the derivative of ( y ) with respect to ( x ) is:

$$
\frac{dy}{dx}
$$

---

### Example: Electricity Bill vs Temperature

Let:

* ( E ) = electricity bill
* ( T ) = temperature

Then the rate of change of electricity bill with temperature is:

$$
\frac{dE}{dT}
$$

This represents how much the electricity bill changes when temperature changes by a very small amount.

---

## Slope (Rise over Run)

The slope of a function measures its rate of change.

For a straight line:

$$
y = mx + c
$$

The slope is:

$$
m = \frac{\Delta y}{\Delta x}
$$

This is also called **rise over run**.

---

### Example

For two points ( (x_1, y_1) ) and ( (x_2, y_2) ), the slope is:

$$
m = \frac{y_2 - y_1}{x_2 - x_1}
$$

---

## Differentiation

**Differentiation** is the process of computing derivatives.

The derivative of a function ( f(x) ) with respect to ( x ) measures how fast ( f(x) ) changes as ( x ) changes:

$$
\frac{df(x)}{dx}
$$

---

## Derivative by First Principle

The derivative of ( f(x) ) at point ( x ) is defined as:

$$
f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
$$

This definition is called the **first principle of derivatives** and is the foundation of all differentiation rules.

---

### Example

Let:

$$
f(x) = x^2
$$

Then,

$$
f'(x) = \lim_{h \to 0} \frac{(x+h)^2 - x^2}{h}
$$

$$
= \lim_{h \to 0} \frac{2xh + h^2}{h}
$$

$$
= \lim_{h \to 0} (2x + h) = 2x
$$

At ( x = 4 ):

$$
f'(4) = 8
$$

---

## Differentiation Rules

Computing derivatives using first principles is tedious. Instead, we use standard differentiation rules.

---

### Power Rule

If:

$$
f(x) = x^r
$$

then:

$$
\frac{d}{dx}(x^r) = r x^{r-1}
$$

---

### Exponential and Logarithmic Functions

$$
\frac{d}{dx}(e^x) = e^x
$$

$$
\frac{d}{dx}(a^x) = a^x \ln a
$$

$$
\frac{d}{dx}(\ln x) = \frac{1}{x}
$$

---

### Trigonometric Functions

$$
\frac{d}{dx}(\sin x) = \cos x
$$

$$
\frac{d}{dx}(\cos x) = -\sin x
$$

$$
\frac{d}{dx}(\tan x) = \sec^2 x
$$

---

## Rules for Combined Functions

### Constant Rule

$$
\frac{d}{dx}(c) = 0
$$

---

### Sum Rule

$$
\frac{d}{dx}[\alpha f(x) + \beta g(x)] = \alpha f'(x) + \beta g'(x)
$$

---

### Product Rule

$$
\frac{d}{dx}[f(x)g(x)] = f'(x)g(x) + f(x)g'(x)
$$

---

### Quotient Rule

$$
\frac{d}{dx}\left(\frac{f(x)}{g(x)}\right)
= \frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2}
$$

---

### Chain Rule

If:

$$
y = f(g(x))
$$

then:

$$
\frac{dy}{dx} = f'(g(x)) \cdot g'(x)
$$

---

## Critical Points: Maxima and Minima

Critical points are points where:

$$
f'(x) = 0
$$

or where the derivative does not exist.

These points may correspond to:

* Maximum
* Minimum
* Point of inflexion

---

### First Derivative Test

Let ( x = a ) be a critical point.

* If ( f'(x) ) changes from **negative to positive**, ( a ) is a **minimum**
* If ( f'(x) ) changes from **positive to negative**, ( a ) is a **maximum**
* If no sign change occurs, it is an **inflexion point**

---

### Second Derivative Test

Compute:

$$
f''(x)
$$

* If ( f''(a) > 0 ), ( a ) is a **minimum**
* If ( f''(a) < 0 ), ( a ) is a **maximum**
* If ( f''(a) = 0 ), the test is inconclusive (often inflexion point)

---

## Importance in Machine Learning

In machine learning, training a model usually means **minimising a cost function**.

Critical points help us find:

$$
\min f(x)
$$

This idea later extends to **multivariable functions**, **gradients**, and **gradient descent**.

---

If you want, next I can:

* Convert this into **PDF-ready LaTeX notes**
* Add **worked ML-style optimisation examples**
* Continue with **Multivariable functions + Gradients** in the same format


---

# Introduction to Multivariable Functions

Until now, you have studied **functions of a single variable**. We now extend this idea to **multivariable functions**.

Most real-world phenomena depend on **more than one variable**. Hence, they are naturally modelled using multivariable functions. In **data science and machine learning**, multivariable calculus is used extensively, especially in:

* Optimisation algorithms
* Parameter and hyperparameter tuning
* Loss and cost functions

---

## Review of Single-Variable Functions

A **single-variable function** maps one input variable to one output variable.

### Definition

If a function maps a real number ( x ) to a real number ( y ), we write:

$$
y = f(x)
$$

Here:

* ( x ) is the **independent variable**
* ( y ) is the **dependent variable**

---

### Example

Consider the function:

$$
y = f(x) = x^3
$$

For different values of ( x ), we get corresponding values of ( y ):

$$
f(1) = 1,\quad f(2) = 8,\quad f(-1) = -1
$$

Visually, this function can be represented as a **curve on a 2D plane**, where:

* The horizontal axis represents ( x )
* The vertical axis represents ( y )

---

## Introduction to Multivariable Functions

A **multivariable function** takes **two or more independent variables** as input and produces a **single output**.

---

### Definition

A function with two variables is written as:

$$
z = f(x, y)
$$

A function with three variables is written as:

$$
w = f(x, y, z)
$$

---

### Example 1: Two-Variable Function

Consider the function:

$$
z = f(x, y) = x^2 + y^2
$$

Here:

* Inputs: ( x ) and ( y )
* Output: ( z )

For the ordered pair ( (x, y) = (3, 2) ):

$$
z = 3^2 + 2^2 = 9 + 4 = 13
$$

This function maps a point ( (x, y) ) in the **2D plane** to a height ( z ), forming a **3D surface**.

---

### Example 2: Three-Variable Function

Consider:

$$
w = f(x, y, z) = x^2 + y + 2z
$$

Here:

* Inputs: ( x, y, z )
* Output: ( w )

This function maps a point in **3D space** to a real number.

---

## Visual Interpretation

* **Single-variable function** → curve in 2D
* **Two-variable function** → surface in 3D
* **Three-variable function** → hypersurface (not directly visualisable)

For the function:

$$
z = x^2 + y^2
$$

* The minimum value occurs at:
  $$
  x = 0,\quad y = 0,\quad z = 0
  $$

* As ( x ) and ( y ) increase, the value of ( z ) increases.

---

## Real-Life Examples of Multivariable Functions

Multivariable functions are used to model many real-world situations.

---

### 1. Mountain Elevation

The elevation of a mountain depends on its geographical coordinates:

$$
\text{Elevation} = f(x, y)
$$

Here:

* ( x, y ): horizontal coordinates
* Output: height (elevation)

---

### 2. Body Mass Index (BMI)

BMI depends on a person’s **weight** and **height**:

$$
\text{BMI}(w, h) = \frac{w}{h^2}
$$

Where:

* ( w ): weight
* ( h ): height

---

### 3. Hospital Bed Requirement

The number of beds required in a hospital may depend on multiple factors:

$$
\text{Beds} = f(\text{season}, \text{flu probability}, \text{population}, \dots)
$$

---

### 4. Store Profit

Profit earned by a store depends on the prices of multiple items:

$$
\text{Profit} = f(p_1, p_2, p_3, \dots)
$$

Where:

* ( p_1, p_2, \dots ): prices of items

---

### 5. Standard of Living

The standard of living depends on several variables:

$$
\text{Standard of Living} = f(\text{income}, \text{expenses}, \text{dependents}, \dots)
$$

---

### 6. Temperature Variation

Temperature at a given time depends on multiple variables:

$$
\text{Temperature} = f(\text{season}, \text{location}, \text{time})
$$

---

## Simple Illustrative Example

A very simple multivariable function is counting fruits:

$$
\text{Fruits} = \text{apples} + \text{oranges}
$$

This shows how **one outcome can depend simultaneously on multiple inputs**.

---

## Summary

* Multivariable functions take **multiple inputs** and produce **one output**
* They naturally model **real-world systems**
* They form the foundation of:

  * Partial derivatives
  * Gradients
  * Optimisation algorithms

---

# Functions of Two Variables

## Introduction

A **function of two variables** takes **two independent variables** as input and produces **one real-valued output**.

Mathematically, this is written as:

$$
z = f(x, y)
$$

Here:

* ( x ) and ( y ) are **independent variables**
* ( z ) is the **dependent variable**

---

## Domain and Range

* The **domain** of a function ( f(x, y) ) is the set of all possible input pairs ( (x, y) )
* The **range** is the set of all output values ( z )

Each input pair ( (x, y) ) corresponds to **exactly one output** ( z ).

---

## Graphical Representation

For a function:

$$
z = f(x, y)
$$

* The **domain** lies in the **( x\text{-}y ) plane**
* The **output** ( z ) is plotted along a third axis

Each point on the graph is represented by an **ordered triplet**:

$$
(x, y, z)
$$

---

### Surface Representation

When we consider **all possible values** of ( (x, y) ) in the domain and compute their corresponding ( z )-values, the resulting graph forms a **surface in three-dimensional space**.

This surface gives a visual intuition of:

* How the output changes with respect to the inputs
* Where the function has **high values**, **low values**, **peaks**, **valleys**, or **saddle points**

---

## Colour Coding on Surfaces

In surface plots:

* **Blue (cool colours)** represent **lower values of ( z )**
* **Pink / warm colours** represent **higher values of ( z )**

Colour gradients help us visually interpret the **height** of the surface at different points.

---

## Examples of Functions of Two Variables

### Example 1: Paraboloid

Consider the function:

$$
z = f(x, y) = x^2 + y^2
$$

* Minimum value occurs at:
  $$
  x = 0,\quad y = 0,\quad z = 0
  $$

* The graph is a **bowl-shaped surface (paraboloid)** opening upwards

* Values of ( z ) increase as we move away from the origin

---

### Example 2: Saddle Surface

Consider the function:

$$
z = f(x, y) = x^2 - y^2
$$

* The graph has a **saddle shape**
* Along the ( x )-direction, the surface curves upward
* Along the ( y )-direction, the surface curves downward

This function has **no global maximum or minimum**, only a **saddle point** at the origin.

---

### Example 3: Mixed Term Function

Consider the function:

$$
z = f(x, y) = x^2 y
$$

* The shape depends on both the sign and magnitude of ( x ) and ( y )
* The surface twists and changes curvature based on input values

---

## Domain and Range Example

Consider the function:

$$
f(x, y) = x - y^2
$$

* The domain is:
  $$
  \mathbb{R}^2
  $$

* The range is:
  $$
  \mathbb{R}
  $$

---

### Graph of the Function

The graph of this function is the set:

$$
{(x, y, z) \in \mathbb{R}^3 \mid z = x - y^2}
$$

This surface shows how the output changes as:

* ( x ) increases linearly
* ( y ) influences ( z ) quadratically

---

## Why Visualisation Matters

Visualising functions of two variables helps us:

* Understand **how outputs change in different directions**
* Identify **peaks, valleys, and saddle points**
* Build intuition for:

  * Partial derivatives
  * Gradients
  * Optimisation algorithms

These ideas are crucial in **machine learning**, where cost functions often depend on **many variables**.

---

## Summary

* Functions of two variables are written as:
  $$
  z = f(x, y)
  $$
* Their graphs are **surfaces in 3D space**
* Each point is an ordered triplet:
  $$
  (x, y, z)
  $$
* Surface plots and colour coding help interpret function behaviour

---


Great — continuing in the **same clean, structured lecture-note style**, with narration removed and **all mathematical expressions enclosed in `$$ … $$`**.

---

# Functions with More Than Two Variables

## Functions of Multiple Variables and Dimensionality

So far, you have studied:

* Functions of **one variable** → curves
* Functions of **two variables** → surfaces

We now extend this idea to **functions of more than two variables**.

---

## Definition

A **multivariable function** with more than two variables takes **three or more independent variables** as input and produces a **single output**.

A function of three variables is written as:

$$
f(x, y, z)
$$

A function of four variables can be written as:

$$
f(x, y, z, t)
$$

In general, a function of ( n ) variables is written as:

$$
f(x_1, x_2, x_3, \dots, x_n)
$$

---

## Example 1: Function of Three Variables

Consider the function:

$$
f(x, y, z) = xy + 2x - z
$$

Here:

* Inputs: ( x, y, z )
* Output: a single real number

Each ordered triple:

$$
(x, y, z)
$$

is mapped to **one real value**:

$$
f(x, y, z) \in \mathbb{R}
$$

---

## Example 2: Function Involving Time

Consider a function where:

* ( x, y ) represent spatial coordinates
* ( t ) represents time

Then the function can be written as:

$$
f(x, y, t)
$$

Such functions are common in:

* Physics
* Climate modelling
* Time-dependent machine learning systems

Here, a point in **space and time** is mapped to a single output value.

---

## Domain and Range

For a function of three variables:

$$
f(x, y, z)
$$

* The **domain** is a subset of:
  $$
  \mathbb{R}^3
  $$

* The **range** is a subset of:
  $$
  \mathbb{R}
  $$

Similarly, for a function of ( n ) variables:

* Domain ⟶ ( \mathbb{R}^n )
* Range ⟶ ( \mathbb{R} )

---

## Visualisation Limitation

* Functions of:

  * **1 variable** → 2D graph
  * **2 variables** → 3D surface

* Functions of **more than two variables** exist in **4 or more dimensions**, which makes **direct visualisation impossible**.

For example:

* A function ( f(x, y, z) ) would require **four dimensions** to visualise
* A function ( f(x, y, z, t) ) would require **five dimensions**

Since humans cannot visualise beyond three spatial dimensions, we rely on **mathematics** instead of geometry.

---

## How Do We Study Such Functions?

Even though we cannot visualise these functions, we can still study them using:

* Partial derivatives
* Gradients
* Directional derivatives
* Optimisation techniques

These tools allow us to:

* Understand how the function changes with respect to each variable
* Find minima and maxima
* Optimise high-dimensional cost functions in machine learning

---

## Importance in Machine Learning

In machine learning, most models depend on **many parameters**:

$$
J(\theta_1, \theta_2, \theta_3, \dots, \theta_n)
$$

Here:

* ( J ) is the **cost (loss) function**
* ( \theta_1, \theta_2, \dots, \theta_n ) are model parameters

Training a model means finding:

$$
\min J(\theta_1, \theta_2, \dots, \theta_n)
$$

This is exactly where **multivariable calculus** becomes essential.

---

## Summary

* Functions with more than two variables map:
  $$
  \mathbb{R}^n \rightarrow \mathbb{R}
  $$
* They cannot be directly visualised
* We rely on **derivatives and algebraic tools** to study them
* These functions form the foundation of **optimisation and learning algorithms**

---

